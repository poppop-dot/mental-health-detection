import gradio as gr
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import os

# =================é…ç½®åŒºåŸŸ=================
# æŒ‡å‘æ‚¨ä¸Šä¸€è½®è®­ç»ƒå‡ºçš„æœ€ä½³æ¨¡å‹è·¯å¾„
MODEL_PATH = "./mentalbert_finetuned_final/final_model"

# å®šä¹‰æ ‡ç­¾æ˜ å°„ (UIæ˜¾ç¤ºç”¨)
LABELS = {
    0: "âœ… å¿ƒç†å¥åº· (Healthy)",
    1: "âš ï¸ å­˜åœ¨é£é™© (Risk)"
}

# =================1. åŠ è½½æ¨¡å‹ (å¯åŠ¨æ—¶è¿è¡Œä¸€æ¬¡)=================
print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH} ...")
try:
    device = "cuda" if torch.cuda.is_available() else "cpu"
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
    model.to(device)
    model.eval()
    print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚é”™è¯¯: {e}")
    exit()

# =================2. å®šä¹‰é¢„æµ‹å‡½æ•° (æ ¸å¿ƒé€»è¾‘)=================
def predict(text):
    if not text:
        return None
    
    # é¢„å¤„ç†
    inputs = tokenizer(
        text, 
        return_tensors="pt", 
        truncation=True, 
        max_length=512
    ).to(device)

    # æ¨ç†
    with torch.no_grad():
        outputs = model(**inputs)
        # ä½¿ç”¨ Softmax å°† logits è½¬ä¸ºæ¦‚ç‡
        probs = F.softmax(outputs.logits, dim=-1)[0]
    
    # Gradio è¦æ±‚è¿”å›ä¸€ä¸ªå­—å…¸: {ç±»åˆ«å: æ¦‚ç‡å€¼}
    return {
        LABELS[0]: float(probs[0]),
        LABELS[1]: float(probs[1])
    }

# =================3. æ„å»º Gradio ç•Œé¢=================
# è‡ªå®šä¹‰ CSS ç¾åŒ–ç•Œé¢ (å¯é€‰)
custom_css = """
#component-0 {max-width: 800px; margin: auto;}
"""

with gr.Blocks(css=custom_css, title="MentalBERT å¿ƒç†å¥åº·æ£€æµ‹") as demo:
    gr.Markdown(
        """
        # ğŸ§  MentalBERT å¿ƒç†å¥åº·é£é™©æ£€æµ‹ç³»ç»Ÿ
        
        åŸºäº **MentalBERT** å¾®è°ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºè¯†åˆ«æ–‡æœ¬ä¸­çš„**æŠ‘éƒå€¾å‘**æˆ–**å¿ƒç†å¥åº·é£é™©**ã€‚
        *(ä»…ä¾›ç ”ç©¶æ¼”ç¤ºï¼Œä¸æ„æˆåŒ»ç–—è¯Šæ–­å»ºè®®)*
        """
    )
    
    with gr.Row():
        with gr.Column():
            input_text = gr.Textbox(
                lines=5, 
                placeholder="è¯·è¾“å…¥æ‚£è€…çš„ä¸»è¯‰ã€æ—¥è®°æˆ–ç¤¾äº¤åª’ä½“æ–‡æœ¬...", 
                label="è¾“å…¥æ–‡æœ¬ (Input Text)"
            )
            submit_btn = gr.Button("å¼€å§‹åˆ†æ (Analyze)", variant="primary")
            
        with gr.Column():
            output_label = gr.Label(num_top_classes=2, label="åˆ†æç»“æœ (Prediction)")
    
    # æ·»åŠ ä¸€äº›ç¤ºä¾‹ï¼Œæ–¹ä¾¿ç‚¹å‡»æµ‹è¯•
    gr.Examples(
        examples=[
            ["I had a great time with my friends today, the food was delicious!"],
            ["I feel so empty and hopeless. I don't know if I can go on."],
            ["The anxiety is keeping me up all night, my chest hurts."],
            ["I'm looking for a job, it's a bit stressful but I'm hopeful."]
        ],
        inputs=input_text,
        outputs=output_label,
        fn=predict,
        cache_examples=False,
    )

    # ç»‘å®šæŒ‰é’®äº‹ä»¶
    submit_btn.click(fn=predict, inputs=input_text, outputs=output_label)

# =================4. å¯åŠ¨æœåŠ¡=================
if __name__ == "__main__":
    print("æ­£åœ¨å¯åŠ¨ Web æœåŠ¡...")
    # server_name="0.0.0.0" å…è®¸å±€åŸŸç½‘è®¿é—®
    # share=True ä¼šç”Ÿæˆä¸€ä¸ªå…è´¹çš„å…¬ç½‘é“¾æ¥ (ç±»ä¼¼ xxxx.gradio.live)
    demo.launch(server_name="0.0.0.0", share=True)